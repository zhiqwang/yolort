
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../_static/javascripts/modernizr.js"></script>
  
  
  
    <title>Deploying yolort on ONNX Runtime &#8212; yolort  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/material.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="../_static/mathjax/tex-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.svg"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Deploying yolort on TensorRT" href="onnx-graphsurgeon-inference-tensorrt.html" />
    <link rel="prev" title="Visualize model graph" href="model-graph-visualization.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=blue data-md-color-accent=light-blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#notebooks/export-onnx-inference-onnxruntime" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../index.html" title="yolort  documentation"
           class="md-header-nav__button md-logo">
          
              <img src="../_static/yolort_logo_icon.png" height="26"
                   alt="yolort documentation logo">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">YOLOv5 Runtime Stack</span>
          <span class="md-header-nav__topic"> Deploying yolort on ONNX Runtime </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/zhiqwang/yolov5-rt-stack/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    yolort
  </div>
</a>
          </div>
        </div>
      
      
  
  <script src="../_static/javascripts/version_dropdown.js"></script>
  <script>
    var json_loc = "../"versions.json"",
        target_loc = "../../",
        text = "Versions";
    $( document ).ready( add_version_dropdown(json_loc, target_loc, text));
  </script>
  

    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
          <li class="md-tabs__item"><a href="../index.html" class="md-tabs__link">yolort  documentation</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../index.html" title="yolort documentation" class="md-nav__button md-logo">
      
        <img src="../_static/yolort_logo_icon.png" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../index.html"
       title="yolort documentation">YOLOv5 Runtime Stack</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/zhiqwang/yolov5-rt-stack/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    yolort
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Getting Started</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../installation.html" class="md-nav__link">Install yolort</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="why-yolort.html" class="md-nav__link">Why yolort?</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Tutorials</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="inference-pytorch-export-libtorch.html" class="md-nav__link">Intuition for yolort</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="comparison-between-yolort-vs-yolov5.html" class="md-nav__link">What is the difference between yolort and yolov5</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="how-to-align-with-ultralytics-yolov5.html" class="md-nav__link">How to align with ultralytics yolov5</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="anchor-label-assignment-visualization.html" class="md-nav__link">Visualize the anchor-target assignment</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="model-graph-visualization.html" class="md-nav__link">Visualize model graph</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Deployment</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    <label class="md-nav__link md-nav__link--active" for="__toc"> Deploying yolort on ONNX Runtime </label>
    
      <a href="#" class="md-nav__link md-nav__link--active">Deploying yolort on ONNX Runtime</a>
      
        
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">Contents</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#notebooks-export-onnx-inference-onnxruntime--page-root" class="md-nav__link">Deploying yolort on ONNX Runtime</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Set-up-environment-and-function-utilities" class="md-nav__link">Set up environment and function utilities</a>
        </li>
        <li class="md-nav__item"><a href="#Load-the-model-trained-from-yolov5" class="md-nav__link">Load the model trained from yolov5</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Inference-on-PyTorch-backend" class="md-nav__link">Inference on PyTorch backend</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Export-the-model-to-ONNX" class="md-nav__link">Export the model to ONNX</a>
        </li>
        <li class="md-nav__item"><a href="#Inference-on-ONNX-Runtime-backend" class="md-nav__link">Inference on ONNX Runtime backend</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Verify-whether-the-inference-results-are-consistent-with-PyTorch’s" class="md-nav__link">Verify whether the inference results are consistent with PyTorch’s</a>
        </li>
        <li class="md-nav__item"><a href="#Verify-another-image" class="md-nav__link">Verify another image</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
  </ul>
</nav>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="onnx-graphsurgeon-inference-tensorrt.html" class="md-nav__link">Deploying yolort on TensorRT</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="export-relay-inference-tvm.html" class="md-nav__link">Deploying yolort on TVM</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">API Reference</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../models.html" class="md-nav__link">yolort.models</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="../models.html#models-structure" class="md-nav__link">Models structure</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="../models.html#yolort.models.YOLOv5" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">YOLOv5()</span></code></a>
      
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../models.html#pre-trained-weights" class="md-nav__link">Pre-trained weights</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="../models.html#yolort.models.yolov5n" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">yolov5n()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../models.html#yolort.models.yolov5n6" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">yolov5n6()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../models.html#yolort.models.yolov5s" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">yolov5s()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../models.html#yolort.models.yolov5s6" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">yolov5s6()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../models.html#yolort.models.yolov5m" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">yolov5m()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../models.html#yolort.models.yolov5m6" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">yolov5m6()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../models.html#yolort.models.yolov5l" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">yolov5l()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../models.html#yolort.models.yolov5ts" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">yolov5ts()</span></code></a>
      
    
    </li></ul>
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html" class="md-nav__link">Modules and utils for YOLOv5</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.AutoShape" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">AutoShape</span></code></a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.AutoShape.classes" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">AutoShape.classes</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.AutoShape.conf" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">AutoShape.conf</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.AutoShape.forward" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">AutoShape.forward()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.AutoShape.iou" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">AutoShape.iou</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.AutoShape.max_det" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">AutoShape.max_det</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.AutoShape.multi_label" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">AutoShape.multi_label</span></code></a>
      
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.Bottleneck" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">Bottleneck</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.BottleneckCSP" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">BottleneckCSP</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.C3" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">C3</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.C3TR" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">C3TR</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.Concat" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">Concat</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.Contract" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">Contract</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.Conv" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">Conv</span></code></a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.Conv.forward_fuse" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">Conv.forward_fuse()</span></code></a>
      
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.DWConv" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">DWConv</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.Detect" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">Detect</span></code></a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.Detect.onnx_dynamic" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">Detect.onnx_dynamic</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.Detect.stride" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">Detect.stride</span></code></a>
      
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.Ensemble" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">Ensemble</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.Expand" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">Expand</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.Focus" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">Focus</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.GhostBottleneck" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">GhostBottleneck</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.GhostConv" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">GhostConv</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.Model" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">Model</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.SPP" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">SPP</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.SPPF" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">SPPF</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.add_yolov5_context" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">add_yolov5_context()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.attempt_download" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">attempt_download()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.focus_transform" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">focus_transform()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.get_yolov5_size" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">get_yolov5_size()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.intersect_dicts" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">intersect_dicts()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.letterbox" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">letterbox()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.load_yolov5_model" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">load_yolov5_model()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.non_max_suppression" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">non_max_suppression()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.scale_coords" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">scale_coords()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.select_device" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">select_device()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.set_logging" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">set_logging()</span></code></a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../yolov5.html#yolort.v5.space_to_depth" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">space_to_depth()</span></code></a>
      
    
    </li></ul>
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">Contents</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#notebooks-export-onnx-inference-onnxruntime--page-root" class="md-nav__link">Deploying yolort on ONNX Runtime</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Set-up-environment-and-function-utilities" class="md-nav__link">Set up environment and function utilities</a>
        </li>
        <li class="md-nav__item"><a href="#Load-the-model-trained-from-yolov5" class="md-nav__link">Load the model trained from yolov5</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Inference-on-PyTorch-backend" class="md-nav__link">Inference on PyTorch backend</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Export-the-model-to-ONNX" class="md-nav__link">Export the model to ONNX</a>
        </li>
        <li class="md-nav__item"><a href="#Inference-on-ONNX-Runtime-backend" class="md-nav__link">Inference on ONNX Runtime backend</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Verify-whether-the-inference-results-are-consistent-with-PyTorch’s" class="md-nav__link">Verify whether the inference results are consistent with PyTorch’s</a>
        </li>
        <li class="md-nav__item"><a href="#Verify-another-image" class="md-nav__link">Verify another image</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<style>
    .nbinput .prompt,
    .nboutput .prompt {
        display: none;
    }
</style><section id="Deploying-yolort-on-ONNX-Runtime">
<h1 id="notebooks-export-onnx-inference-onnxruntime--page-root">Deploying yolort on ONNX Runtime<a class="headerlink" href="#notebooks-export-onnx-inference-onnxruntime--page-root" title="Permalink to this heading">¶</a></h1>
<p>The ONNX model exported by yolort differs from other pipeline in the following three ways.</p>
<ul class="simple">
<li><p>We embed the pre-processing into the graph (mainly composed of <code class="docutils literal notranslate"><span class="pre">letterbox</span></code>). and the exported model expects a <code class="docutils literal notranslate"><span class="pre">Tensor[C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>, which is in <code class="docutils literal notranslate"><span class="pre">RGB</span></code> channel and is rescaled to range <code class="docutils literal notranslate"><span class="pre">float32</span> <span class="pre">[0-1]</span></code>.</p></li>
<li><p>We embed the post-processing into the model graph with <code class="docutils literal notranslate"><span class="pre">torchvision.ops.batched_nms</span></code>. So the outputs of the exported model are straightforward <code class="docutils literal notranslate"><span class="pre">boxes</span></code>, <code class="docutils literal notranslate"><span class="pre">labels</span></code> and <code class="docutils literal notranslate"><span class="pre">scores</span></code> fields of this image.</p></li>
<li><p>We adopt the dynamic shape mechanism to export the ONNX models.</p></li>
</ul>
<section id="Set-up-environment-and-function-utilities">
<h2 id="Set-up-environment-and-function-utilities">Set up environment and function utilities<a class="headerlink" href="#Set-up-environment-and-function-utilities" title="Permalink to this heading">¶</a></h2>
<p>First you should install ONNX Runtime first to run this tutorial. See the ONNX Runtime <a class="reference external" href="https://onnxruntime.ai">installation matrix</a> for recommended instructions for desired combinations of target operating system, hardware, accelerator, and language.</p>
<p>A quick solution is to install via pip on X64:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install onnxruntime
</pre></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"CUDA_DEVICE_ORDER"</span><span class="p">]</span><span class="o">=</span><span class="s2">"PCI_BUS_ID"</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"CUDA_VISIBLE_DEVICES"</span><span class="p">]</span><span class="o">=</span><span class="s2">"0"</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">import</span> <span class="nn">onnxruntime</span>

<span class="kn">from</span> <span class="nn">yolort.models</span> <span class="kn">import</span> <span class="n">YOLOv5</span>
<span class="kn">from</span> <span class="nn">yolort.v5</span> <span class="kn">import</span> <span class="n">attempt_download</span>

<span class="kn">from</span> <span class="nn">yolort.utils</span> <span class="kn">import</span> <span class="n">get_image_from_url</span><span class="p">,</span> <span class="n">read_image_to_tensor</span>
<span class="kn">from</span> <span class="nn">yolort.utils.image_utils</span> <span class="kn">import</span> <span class="n">to_numpy</span>
</pre></div>
</div>
</div>
<p>Define some parameters used for defining the model, exporting ONNX models and inferencing on ONNX Runtime.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img_size</span> <span class="o">=</span> <span class="mi">640</span>
<span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">img_size</span><span class="p">,</span> <span class="n">img_size</span><span class="p">)</span>  <span class="c1"># Used for pre-processing</span>
<span class="n">size_divisible</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">score_thresh</span> <span class="o">=</span> <span class="mf">0.35</span>
<span class="n">nms_thresh</span> <span class="o">=</span> <span class="mf">0.45</span>
<span class="n">opset_version</span> <span class="o">=</span> <span class="mi">11</span>
</pre></div>
</div>
</div>
<p>Get images for inferenceing.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img_src1</span> <span class="o">=</span> <span class="s2">"https://huggingface.co/spaces/zhiqwang/assets/resolve/main/bus.jpg"</span>
<span class="n">img_one</span> <span class="o">=</span> <span class="n">get_image_from_url</span><span class="p">(</span><span class="n">img_src1</span><span class="p">)</span>
<span class="n">img_one</span> <span class="o">=</span> <span class="n">read_image_to_tensor</span><span class="p">(</span><span class="n">img_one</span><span class="p">,</span> <span class="n">is_half</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">img_one</span> <span class="o">=</span> <span class="n">img_one</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">img_src2</span> <span class="o">=</span> <span class="s2">"https://huggingface.co/spaces/zhiqwang/assets/resolve/main/zidane.jpg"</span>
<span class="n">img_two</span> <span class="o">=</span> <span class="n">get_image_from_url</span><span class="p">(</span><span class="n">img_src2</span><span class="p">)</span>
<span class="n">img_two</span> <span class="o">=</span> <span class="n">read_image_to_tensor</span><span class="p">(</span><span class="n">img_two</span><span class="p">,</span> <span class="n">is_half</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">img_two</span> <span class="o">=</span> <span class="n">img_two</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Load-the-model-trained-from-yolov5">
<h2 id="Load-the-model-trained-from-yolov5">Load the model trained from yolov5<a class="headerlink" href="#Load-the-model-trained-from-yolov5" title="Permalink to this heading">¶</a></h2>
<p>The model used below is officially released by yolov5 and trained on COCO 2017 datasets.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># yolov5n6.pt is downloaded from 'https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5n6.pt'</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="s2">"yolov5n6.pt"</span>
<span class="n">onnx_path</span> <span class="o">=</span> <span class="s2">"yolov5n6.onnx"</span>
<span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">attempt_download</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">YOLOv5</span><span class="o">.</span><span class="n">load_from_yolov5</span><span class="p">(</span>
    <span class="n">model_path</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
    <span class="n">size_divisible</span><span class="o">=</span><span class="n">size_divisible</span><span class="p">,</span>
    <span class="n">score_thresh</span><span class="o">=</span><span class="n">score_thresh</span><span class="p">,</span>
    <span class="n">nms_thresh</span><span class="o">=</span><span class="n">nms_thresh</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

                 from  n    params  module                                  arguments
  0                -1  1      1760  yolort.v5.models.common.Conv            [3, 16, 6, 2, 2]
  1                -1  1      4672  yolort.v5.models.common.Conv            [16, 32, 3, 2]
  2                -1  1      4800  yolort.v5.models.common.C3              [32, 32, 1]
  3                -1  1     18560  yolort.v5.models.common.Conv            [32, 64, 3, 2]
  4                -1  2     29184  yolort.v5.models.common.C3              [64, 64, 2]
  5                -1  1     73984  yolort.v5.models.common.Conv            [64, 128, 3, 2]
  6                -1  3    156928  yolort.v5.models.common.C3              [128, 128, 3]
  7                -1  1    221568  yolort.v5.models.common.Conv            [128, 192, 3, 2]
  8                -1  1    167040  yolort.v5.models.common.C3              [192, 192, 1]
  9                -1  1    442880  yolort.v5.models.common.Conv            [192, 256, 3, 2]
 10                -1  1    296448  yolort.v5.models.common.C3              [256, 256, 1]
 11                -1  1    164608  yolort.v5.models.common.SPPF            [256, 256, 5]
 12                -1  1     49536  yolort.v5.models.common.Conv            [256, 192, 1, 1]
 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 14           [-1, 8]  1         0  yolort.v5.models.common.Concat          [1]
 15                -1  1    203904  yolort.v5.models.common.C3              [384, 192, 1, False]
 16                -1  1     24832  yolort.v5.models.common.Conv            [192, 128, 1, 1]
 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 18           [-1, 6]  1         0  yolort.v5.models.common.Concat          [1]
 19                -1  1     90880  yolort.v5.models.common.C3              [256, 128, 1, False]
 20                -1  1      8320  yolort.v5.models.common.Conv            [128, 64, 1, 1]
 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 22           [-1, 4]  1         0  yolort.v5.models.common.Concat          [1]
 23                -1  1     22912  yolort.v5.models.common.C3              [128, 64, 1, False]
 24                -1  1     36992  yolort.v5.models.common.Conv            [64, 64, 3, 2]
 25          [-1, 20]  1         0  yolort.v5.models.common.Concat          [1]
 26                -1  1     74496  yolort.v5.models.common.C3              [128, 128, 1, False]
 27                -1  1    147712  yolort.v5.models.common.Conv            [128, 128, 3, 2]
 28          [-1, 16]  1         0  yolort.v5.models.common.Concat          [1]
 29                -1  1    179328  yolort.v5.models.common.C3              [256, 192, 1, False]
 30                -1  1    332160  yolort.v5.models.common.Conv            [192, 192, 3, 2]
 31          [-1, 12]  1         0  yolort.v5.models.common.Concat          [1]
 32                -1  1    329216  yolort.v5.models.common.C3              [384, 256, 1, False]
 33  [23, 26, 29, 32]  1    164220  yolort.v5.models.yolo.Detect            [80, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [64, 128, 192, 256]]
/opt/conda/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model Summary: 355 layers, 3246940 parameters, 3246940 gradients, 4.6 GFLOPs

</pre></div></div>
</div>
<section id="Inference-on-PyTorch-backend">
<h3 id="Inference-on-PyTorch-backend">Inference on PyTorch backend<a class="headerlink" href="#Inference-on-PyTorch-backend" title="Permalink to this heading">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">img_one</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">model_out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">model_out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The slowest run took 5.09 times longer than the fastest. This could mean that an intermediate result is being cached.
115 ms ± 71 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_out</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'boxes'</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[ 32.27846, 225.15266, 811.47729, 740.91071],
        [ 50.42178, 387.48898, 241.54399, 897.61041],
        [219.03331, 386.14346, 345.77689, 869.02582],
        [678.05023, 374.65326, 809.80334, 874.80621]])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_out</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'scores'</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([0.88238, 0.84486, 0.72629, 0.70077])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_out</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'labels'</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([5, 0, 0, 0])
</pre></div></div>
</div>
</section>
</section>
<section id="Export-the-model-to-ONNX">
<h2 id="Export-the-model-to-ONNX">Export the model to ONNX<a class="headerlink" href="#Export-the-model-to-ONNX" title="Permalink to this heading">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">yolort.runtime.ort_helper</span> <span class="kn">import</span> <span class="n">export_onnx</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'We are using opset version: </span><span class="si">{</span><span class="n">opset_version</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
We are using opset version: 11
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">export_onnx</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">onnx_path</span><span class="o">=</span><span class="n">onnx_path</span><span class="p">,</span> <span class="n">opset_version</span><span class="o">=</span><span class="n">opset_version</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:3701: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  (torch.floor((input.size(i + 2).float() * torch.tensor(scale_factors[i], dtype=torch.float32)).float()))
/coding/yolov5-rt-stack/yolort/models/transform.py:282: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  img_h, img_w = _get_shape_onnx(img)
/coding/yolov5-rt-stack/yolort/models/anchor_utils.py:45: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  anchors = torch.as_tensor(self.anchor_grids, dtype=torch.float32, device=device).to(dtype=dtype)
/coding/yolov5-rt-stack/yolort/models/anchor_utils.py:46: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  strides = torch.as_tensor(self.strides, dtype=torch.float32, device=device).to(dtype=dtype)
/coding/yolov5-rt-stack/yolort/models/box_head.py:402: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  strides = torch.as_tensor(self.strides, dtype=torch.float32, device=device).to(dtype=dtype)
/coding/yolov5-rt-stack/yolort/models/box_head.py:333: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  for head_output, grid, shift, stride in zip(head_outputs, grids, shifts, strides):
/opt/conda/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py:2815: UserWarning: Exporting aten::index operator of advanced indexing in opset 11 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.
  warnings.warn("Exporting aten::index operator of advanced indexing in opset " +
</pre></div></div>
</div>
<p>Check the exported ONNX model is well formed</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the ONNX model</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">onnx_path</span><span class="p">)</span>

<span class="c1"># Check that the model is well formed</span>
<span class="n">onnx</span><span class="o">.</span><span class="n">checker</span><span class="o">.</span><span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

<span class="c1"># Print a human readable representation of the graph</span>
<span class="c1"># print(onnx.helper.printable_graph(model.graph))</span>
</pre></div>
</div>
</div>
</section>
<section id="Inference-on-ONNX-Runtime-backend">
<h2 id="Inference-on-ONNX-Runtime-backend">Inference on ONNX Runtime backend<a class="headerlink" href="#Inference-on-ONNX-Runtime-backend" title="Permalink to this heading">¶</a></h2>
<p>Check the version of ONNX Runtime first.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Starting with onnx </span><span class="si">{</span><span class="n">onnx</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s1">, onnxruntime </span><span class="si">{</span><span class="n">onnxruntime</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s1">...'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Starting with onnx 1.10.2, onnxruntime 1.10.0...
</pre></div></div>
</div>
<p>Prepare the inputs for ONNX Runtime.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">_flatten</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
<span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">_flatten</span><span class="p">(</span><span class="n">model_out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">,</span> <span class="n">inputs</span><span class="p">))</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">,</span> <span class="n">outputs</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>We provide a pipeline for deploying yolort with ONNX Runtime.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">yolort.runtime</span> <span class="kn">import</span> <span class="n">PredictorORT</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_runtime</span> <span class="o">=</span> <span class="n">PredictorORT</span><span class="p">(</span><span class="n">onnx_path</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">"cpu"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Providers was initialized.
Set inference device to CPU
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ort_outs1</span> <span class="o">=</span> <span class="n">y_runtime</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let’s measure the inferencing speed of ONNX Runtime.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it
<span class="n">y_runtime</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
47.7 ms ± 614 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
</pre></div></div>
</div>
<section id="Verify-whether-the-inference-results-are-consistent-with-PyTorch’s">
<h3 id="Verify-whether-the-inference-results-are-consistent-with-PyTorch’s">Verify whether the inference results are consistent with PyTorch’s<a class="headerlink" href="#Verify-whether-the-inference-results-are-consistent-with-PyTorch’s" title="Permalink to this heading">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)):</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ort_outs1</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-04</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-07</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Exported model has been tested with ONNXRuntime, and the result looks good!"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Exported model has been tested with ONNXRuntime, and the result looks good!
</pre></div></div>
</div>
</section>
<section id="Verify-another-image">
<h3 id="Verify-another-image">Verify another image<a class="headerlink" href="#Verify-another-image" title="Permalink to this heading">¶</a></h3>
<p>When using dynamic shape inference in trace mode, the shape inference mechanism for some operators may not work, so we verify it once for another image with a different shape as well.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">img_two</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">out_pytorch</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">_flatten</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
<span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">_flatten</span><span class="p">(</span><span class="n">out_pytorch</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">,</span> <span class="n">inputs</span><span class="p">))</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">,</span> <span class="n">outputs</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>Compute onnxruntime output prediction.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ort_outs2</span> <span class="o">=</span> <span class="n">y_runtime</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let’s measure the inferencing speed of ONNX Runtime.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it
<span class="n">y_runtime</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
37.5 ms ± 767 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
</pre></div></div>
</div>
<p>Verify whether the inference results are consistent with PyTorch’s.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)):</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ort_outs2</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-04</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-07</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Exported model has been tested with ONNXRuntime, and the result looks good!"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Exported model has been tested with ONNXRuntime, and the result looks good!
</pre></div></div>
</div>
</section>
</section>
</section>
<p>View this document as a notebook:
<a class="reference external" href="https://github.com/zhiqwang/yolov5-rt-stack/blob/main/notebooks/export-onnx-inference-onnxruntime.ipynb">https://github.com/zhiqwang/yolov5-rt-stack/blob/main/notebooks/export-onnx-inference-onnxruntime.ipynb</a></p>
<hr class="docutils"/>


          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
            <a href="model-graph-visualization.html" title="Visualize model graph"
               class="md-flex md-footer-nav__link md-footer-nav__link--prev"
               rel="prev">
              <div class="md-flex__cell md-flex__cell--shrink">
                <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
              </div>
              <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
                <span class="md-flex__ellipsis">
                  <span
                      class="md-footer-nav__direction"> Previous </span> Visualize model graph </span>
              </div>
            </a>
          
          
            <a href="onnx-graphsurgeon-inference-tensorrt.html" title="Deploying yolort on TensorRT"
               class="md-flex md-footer-nav__link md-footer-nav__link--next"
               rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span
                class="md-flex__ellipsis"> <span
                class="md-footer-nav__direction"> Next </span> Deploying yolort on TensorRT </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink"><i
                class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2022, yolort team.
              
          </div>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 5.3.0.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>