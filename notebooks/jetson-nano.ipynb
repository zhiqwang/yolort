{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea6ca2d6",
   "metadata": {},
   "source": [
    "# 利用 trtexec 导出 engine 并进行推理 输入图片尺寸 320x320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249e2fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --onnx=yolov5n.trt.onnx --saveEngine=yolov5n_320_trtexec.engine --workspace=8192\n",
      "[03/11/2022-21:31:30] [I] === Model Options ===\n",
      "[03/11/2022-21:31:30] [I] Format: ONNX\n",
      "[03/11/2022-21:31:30] [I] Model: yolov5n.trt.onnx\n",
      "[03/11/2022-21:31:30] [I] Output:\n",
      "[03/11/2022-21:31:30] [I] === Build Options ===\n",
      "[03/11/2022-21:31:30] [I] Max batch: explicit batch\n",
      "[03/11/2022-21:31:30] [I] Workspace: 8192 MiB\n",
      "[03/11/2022-21:31:30] [I] minTiming: 1\n",
      "[03/11/2022-21:31:30] [I] avgTiming: 8\n",
      "[03/11/2022-21:31:30] [I] Precision: FP32\n",
      "[03/11/2022-21:31:30] [I] Calibration: \n",
      "[03/11/2022-21:31:30] [I] Refit: Disabled\n",
      "[03/11/2022-21:31:30] [I] Sparsity: Disabled\n",
      "[03/11/2022-21:31:30] [I] Safe mode: Disabled\n",
      "[03/11/2022-21:31:30] [I] DirectIO mode: Disabled\n",
      "[03/11/2022-21:31:30] [I] Restricted mode: Disabled\n",
      "[03/11/2022-21:31:30] [I] Save engine: yolov5n_320_trtexec.engine\n",
      "[03/11/2022-21:31:30] [I] Load engine: \n",
      "[03/11/2022-21:31:30] [I] Profiling verbosity: 0\n",
      "[03/11/2022-21:31:30] [I] Tactic sources: Using default tactic sources\n",
      "[03/11/2022-21:31:30] [I] timingCacheMode: local\n",
      "[03/11/2022-21:31:30] [I] timingCacheFile: \n",
      "[03/11/2022-21:31:30] [I] Input(s)s format: fp32:CHW\n",
      "[03/11/2022-21:31:30] [I] Output(s)s format: fp32:CHW\n",
      "[03/11/2022-21:31:30] [I] Input build shapes: model\n",
      "[03/11/2022-21:31:30] [I] Input calibration shapes: model\n",
      "[03/11/2022-21:31:30] [I] === System Options ===\n",
      "[03/11/2022-21:31:30] [I] Device: 0\n",
      "[03/11/2022-21:31:30] [I] DLACore: \n",
      "[03/11/2022-21:31:30] [I] Plugins:\n",
      "[03/11/2022-21:31:30] [I] === Inference Options ===\n",
      "[03/11/2022-21:31:30] [I] Batch: Explicit\n",
      "[03/11/2022-21:31:30] [I] Input inference shapes: model\n",
      "[03/11/2022-21:31:30] [I] Iterations: 10\n",
      "[03/11/2022-21:31:30] [I] Duration: 3s (+ 200ms warm up)\n",
      "[03/11/2022-21:31:30] [I] Sleep time: 0ms\n",
      "[03/11/2022-21:31:30] [I] Idle time: 0ms\n",
      "[03/11/2022-21:31:30] [I] Streams: 1\n",
      "[03/11/2022-21:31:30] [I] ExposeDMA: Disabled\n",
      "[03/11/2022-21:31:30] [I] Data transfers: Enabled\n",
      "[03/11/2022-21:31:30] [I] Spin-wait: Disabled\n",
      "[03/11/2022-21:31:30] [I] Multithreading: Disabled\n",
      "[03/11/2022-21:31:30] [I] CUDA Graph: Disabled\n",
      "[03/11/2022-21:31:30] [I] Separate profiling: Disabled\n",
      "[03/11/2022-21:31:30] [I] Time Deserialize: Disabled\n",
      "[03/11/2022-21:31:30] [I] Time Refit: Disabled\n",
      "[03/11/2022-21:31:30] [I] Skip inference: Disabled\n",
      "[03/11/2022-21:31:30] [I] Inputs:\n",
      "[03/11/2022-21:31:30] [I] === Reporting Options ===\n",
      "[03/11/2022-21:31:30] [I] Verbose: Disabled\n",
      "[03/11/2022-21:31:30] [I] Averages: 10 inferences\n",
      "[03/11/2022-21:31:30] [I] Percentile: 99\n",
      "[03/11/2022-21:31:30] [I] Dump refittable layers:Disabled\n",
      "[03/11/2022-21:31:30] [I] Dump output: Disabled\n",
      "[03/11/2022-21:31:30] [I] Profile: Disabled\n",
      "[03/11/2022-21:31:30] [I] Export timing to JSON file: \n",
      "[03/11/2022-21:31:30] [I] Export output to JSON file: \n",
      "[03/11/2022-21:31:30] [I] Export profile to JSON file: \n",
      "[03/11/2022-21:31:30] [I] \n",
      "[03/11/2022-21:31:30] [I] === Device Information ===\n",
      "[03/11/2022-21:31:30] [I] Selected Device: NVIDIA Tegra X1\n",
      "[03/11/2022-21:31:30] [I] Compute Capability: 5.3\n",
      "[03/11/2022-21:31:30] [I] SMs: 1\n",
      "[03/11/2022-21:31:30] [I] Compute Clock Rate: 0.9216 GHz\n",
      "[03/11/2022-21:31:30] [I] Device Global Memory: 3956 MiB\n",
      "[03/11/2022-21:31:30] [I] Shared Memory per SM: 64 KiB\n",
      "[03/11/2022-21:31:30] [I] Memory Bus Width: 64 bits (ECC disabled)\n",
      "[03/11/2022-21:31:30] [I] Memory Clock Rate: 0.01275 GHz\n",
      "[03/11/2022-21:31:30] [I] \n",
      "[03/11/2022-21:31:30] [I] TensorRT version: 8.2.1\n",
      "[03/11/2022-21:31:31] [I] [TRT] [MemUsageChange] Init CUDA: CPU +229, GPU +0, now: CPU 248, GPU 2772 (MiB)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 248 MiB, GPU 2800 MiB\n",
      "[03/11/2022-21:31:32] [I] [TRT] [MemUsageSnapshot] End constructing builder kernel library: CPU 278 MiB, GPU 2830 MiB\n",
      "[03/11/2022-21:31:32] [I] Start parsing network model\n",
      "[03/11/2022-21:31:32] [I] [TRT] ----------------------------------------------------------------\n",
      "[03/11/2022-21:31:32] [I] [TRT] Input filename:   yolov5n.trt.onnx\n",
      "[03/11/2022-21:31:32] [I] [TRT] ONNX IR version:  0.0.8\n",
      "[03/11/2022-21:31:32] [I] [TRT] Opset version:    11\n",
      "[03/11/2022-21:31:32] [I] [TRT] Producer name:    \n",
      "[03/11/2022-21:31:32] [I] [TRT] Producer version: \n",
      "[03/11/2022-21:31:32] [I] [TRT] Domain:           \n",
      "[03/11/2022-21:31:32] [I] [TRT] Model version:    0\n",
      "[03/11/2022-21:31:32] [I] [TRT] Doc string:       \n",
      "[03/11/2022-21:31:32] [I] [TRT] ----------------------------------------------------------------\n",
      "[03/11/2022-21:31:32] [W] [TRT] onnx2trt_utils.cpp:366: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[03/11/2022-21:31:32] [W] [TRT] onnx2trt_utils.cpp:392: One or more weights outside the range of INT32 was clamped\n",
      "[03/11/2022-21:31:32] [W] [TRT] onnx2trt_utils.cpp:392: One or more weights outside the range of INT32 was clamped\n",
      "[03/11/2022-21:31:32] [W] [TRT] onnx2trt_utils.cpp:392: One or more weights outside the range of INT32 was clamped\n",
      "[03/11/2022-21:31:32] [W] [TRT] onnx2trt_utils.cpp:392: One or more weights outside the range of INT32 was clamped\n",
      "[03/11/2022-21:31:32] [I] [TRT] No importer registered for op: EfficientNMS_TRT. Attempting to import as plugin.\n",
      "[03/11/2022-21:31:32] [I] [TRT] Searching for plugin: EfficientNMS_TRT, plugin_version: 1, plugin_namespace: \n",
      "[03/11/2022-21:31:32] [I] [TRT] Successfully created plugin: EfficientNMS_TRT\n",
      "[03/11/2022-21:31:32] [I] Finish parsing network model\n",
      "[03/11/2022-21:31:32] [I] [TRT] ---------- Layers Running on DLA ----------\n",
      "[03/11/2022-21:31:32] [I] [TRT] ---------- Layers Running on GPU ----------\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_0\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_1), Mul_2)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_3\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_4), Mul_5)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_16 || Conv_6\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_7), Mul_8)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_9\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_10), Mul_11)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_12\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_17), Mul_18)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(PWN(Sigmoid_13), Mul_14), Add_15)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] 369 copy\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_20\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_21), Mul_22)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_23\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_24), Mul_25)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_43 || Conv_26\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_27), Mul_28)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_29\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_30), Mul_31)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_32\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(PWN(Sigmoid_33), Mul_34), Add_35)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_36\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_37), Mul_38)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_39\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_44), Mul_45)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(PWN(Sigmoid_40), Mul_41), Add_42)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_47\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_48), Mul_49)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_50\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_51), Mul_52)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_77 || Conv_53\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_54), Mul_55)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_56\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_57), Mul_58)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_59\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(PWN(Sigmoid_60), Mul_61), Add_62)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_63\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_64), Mul_65)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_66\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(PWN(Sigmoid_67), Mul_68), Add_69)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_70\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_71), Mul_72)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_73\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_78), Mul_79)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(PWN(Sigmoid_74), Mul_75), Add_76)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_81\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_82), Mul_83)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_84\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_85), Mul_86)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_97 || Conv_87\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_88), Mul_89)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_90\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_91), Mul_92)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_93\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_98), Mul_99)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(PWN(Sigmoid_94), Mul_95), Add_96)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_101\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_102), Mul_103)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_104\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_105), Mul_106)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] MaxPool_109\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] MaxPool_108\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] MaxPool_107\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] 487 copy\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] 488 copy\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] 489 copy\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] 490 copy\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_111\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_112), Mul_113)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_114\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_115), Mul_116)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Resize_118\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] 504 copy\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_129 || Conv_120\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_121), Mul_122)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_123\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_124), Mul_125)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_126\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_130), Mul_131)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_127), Mul_128)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_133\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_134), Mul_135)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_136\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_137), Mul_138)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Resize_140\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] 535 copy\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_151 || Conv_142\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_143), Mul_144)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_145\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_146), Mul_147)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_148\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_152), Mul_153)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_149), Mul_150)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_155\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_156), Mul_157)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_198\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_158\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_159), Mul_160)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] 530 copy\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_171 || Conv_162\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_163), Mul_164)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_165\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_166), Mul_167)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_168\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_172), Mul_173)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_169), Mul_170)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_175\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_176), Mul_177)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_201\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_178\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_179), Mul_180)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] 499 copy\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_191 || Conv_182\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_183), Mul_184)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_185\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_186), Mul_187)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_188\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_192), Mul_193)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_189), Mul_190)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_195\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] PWN(PWN(Sigmoid_196), Mul_197)\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] Conv_204\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] {ForeignNode[Reshape_199 + Transpose_200...Concat_408]}\n",
      "[03/11/2022-21:31:32] [I] [TRT] [GpuLayer] batched_nms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/11/2022-21:31:33] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +158, GPU +146, now: CPU 446, GPU 3008 (MiB)\n",
      "[03/11/2022-21:31:35] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +240, GPU +246, now: CPU 686, GPU 3254 (MiB)\n",
      "[03/11/2022-21:31:35] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[03/11/2022-21:33:57] [I] [TRT] Detected 1 inputs and 4 output network tensors.\n",
      "[03/11/2022-21:33:57] [I] [TRT] Total Host Persistent Memory: 154592\n",
      "[03/11/2022-21:33:57] [I] [TRT] Total Device Persistent Memory: 6233088\n",
      "[03/11/2022-21:33:57] [I] [TRT] Total Scratch Memory: 12096768\n",
      "[03/11/2022-21:33:57] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 535 MiB\n",
      "[03/11/2022-21:33:57] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 49.5465ms to assign 7 blocks to 112 nodes requiring 16513536 bytes.\n",
      "[03/11/2022-21:33:57] [I] [TRT] Total Activation Memory: 16513536\n",
      "[03/11/2022-21:33:57] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 958, GPU 3433 (MiB)\n",
      "[03/11/2022-21:33:57] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +0, now: CPU 959, GPU 3433 (MiB)\n",
      "[03/11/2022-21:33:57] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +8, now: CPU 0, GPU 8 (MiB)\n",
      "[03/11/2022-21:33:57] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 957, GPU 3442 (MiB)\n",
      "[03/11/2022-21:33:57] [I] [TRT] Loaded engine size: 9 MiB\n",
      "[03/11/2022-21:33:57] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 964, GPU 3442 (MiB)\n",
      "[03/11/2022-21:33:57] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 964, GPU 3442 (MiB)\n",
      "[03/11/2022-21:33:57] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +7, now: CPU 0, GPU 7 (MiB)\n",
      "[03/11/2022-21:33:57] [I] Engine built in 147.811 sec.\n",
      "[03/11/2022-21:33:57] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 926, GPU 3452 (MiB)\n",
      "[03/11/2022-21:33:57] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 926, GPU 3452 (MiB)\n",
      "[03/11/2022-21:33:58] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +22, now: CPU 0, GPU 29 (MiB)\n",
      "[03/11/2022-21:33:58] [I] Using random values for input images\n",
      "[03/11/2022-21:33:58] [I] Created input binding for images with dimensions 1x3x320x320\n",
      "[03/11/2022-21:33:58] [I] Using random values for output num_detections\n",
      "[03/11/2022-21:33:58] [I] Created output binding for num_detections with dimensions 1x1\n",
      "[03/11/2022-21:33:58] [I] Using random values for output detection_boxes\n",
      "[03/11/2022-21:33:58] [I] Created output binding for detection_boxes with dimensions 1x100x4\n",
      "[03/11/2022-21:33:58] [I] Using random values for output detection_scores\n",
      "[03/11/2022-21:33:58] [I] Created output binding for detection_scores with dimensions 1x100\n",
      "[03/11/2022-21:33:58] [I] Using random values for output detection_classes\n",
      "[03/11/2022-21:33:58] [I] Created output binding for detection_classes with dimensions 1x100\n",
      "[03/11/2022-21:33:58] [I] Starting inference\n",
      "[03/11/2022-21:34:01] [I] Warmup completed 12 queries over 200 ms\n",
      "[03/11/2022-21:34:01] [I] Timing trace has 175 queries over 3.02385 s\n",
      "[03/11/2022-21:34:01] [I] \n",
      "[03/11/2022-21:34:01] [I] === Trace details ===\n",
      "[03/11/2022-21:34:01] [I] Trace averages of 10 runs:\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.7271 ms - Host latency: 15.8549 ms (end to end 17.2744 ms, enqueue 4.77378 ms)\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.729 ms - Host latency: 15.8581 ms (end to end 17.2728 ms, enqueue 4.76854 ms)\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.7362 ms - Host latency: 15.8642 ms (end to end 17.2773 ms, enqueue 4.69489 ms)\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.7307 ms - Host latency: 15.8595 ms (end to end 17.2766 ms, enqueue 4.74559 ms)\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.7256 ms - Host latency: 15.8537 ms (end to end 17.2713 ms, enqueue 5.42311 ms)\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.7268 ms - Host latency: 15.8545 ms (end to end 17.2721 ms, enqueue 5.57074 ms)\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.7283 ms - Host latency: 15.8561 ms (end to end 17.2735 ms, enqueue 5.53254 ms)\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.7315 ms - Host latency: 15.8598 ms (end to end 17.2762 ms, enqueue 4.76522 ms)\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.7339 ms - Host latency: 15.8621 ms (end to end 17.2781 ms, enqueue 4.92166 ms)\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.729 ms - Host latency: 15.8575 ms (end to end 17.2735 ms, enqueue 4.73936 ms)\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.9435 ms - Host latency: 16.0722 ms (end to end 17.5222 ms, enqueue 5.24183 ms)\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.7466 ms - Host latency: 15.8755 ms (end to end 17.2915 ms, enqueue 5.87759 ms)\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.7272 ms - Host latency: 15.8552 ms (end to end 17.2725 ms, enqueue 5.8343 ms)\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.7327 ms - Host latency: 15.8606 ms (end to end 17.2761 ms, enqueue 5.80186 ms)\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.7288 ms - Host latency: 15.8572 ms (end to end 17.2755 ms, enqueue 5.40298 ms)\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.7308 ms - Host latency: 15.859 ms (end to end 17.2742 ms, enqueue 4.74592 ms)\n",
      "[03/11/2022-21:34:01] [I] Average on 10 runs - GPU latency: 15.7281 ms - Host latency: 15.8556 ms (end to end 17.2724 ms, enqueue 5.33894 ms)\n",
      "[03/11/2022-21:34:01] [I] \n",
      "[03/11/2022-21:34:01] [I] === Performance summary ===\n",
      "[03/11/2022-21:34:01] [I] Throughput: 57.8733 qps\n",
      "[03/11/2022-21:34:01] [I] Latency: min = 15.3352 ms, max = 17.2869 ms, mean = 15.8682 ms, median = 15.8593 ms, percentile(99%) = 16.5825 ms\n",
      "[03/11/2022-21:34:01] [I] End-to-End Host Latency: min = 15.344 ms, max = 18.7014 ms, mean = 17.2785 ms, median = 17.2749 ms, percentile(99%) = 18.3315 ms\n",
      "[03/11/2022-21:34:01] [I] Enqueue Time: min = 4.52441 ms, max = 6.30054 ms, mean = 5.19274 ms, median = 4.94029 ms, percentile(99%) = 6.2439 ms\n",
      "[03/11/2022-21:34:01] [I] H2D Latency: min = 0.116455 ms, max = 0.126648 ms, mean = 0.119954 ms, median = 0.119873 ms, percentile(99%) = 0.126617 ms\n",
      "[03/11/2022-21:34:01] [I] GPU Compute Time: min = 15.2095 ms, max = 17.1589 ms, mean = 15.74 ms, median = 15.7307 ms, percentile(99%) = 16.449 ms\n",
      "[03/11/2022-21:34:01] [I] D2H Latency: min = 0.00537109 ms, max = 0.00933838 ms, mean = 0.00825047 ms, median = 0.00830078 ms, percentile(99%) = 0.00927734 ms\n",
      "[03/11/2022-21:34:01] [I] Total Host Walltime: 3.02385 s\n",
      "[03/11/2022-21:34:01] [I] Total GPU Compute Time: 2.75449 s\n",
      "[03/11/2022-21:34:01] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[03/11/2022-21:34:01] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --onnx=yolov5n.trt.onnx --saveEngine=yolov5n_320_trtexec.engine --workspace=8192\n"
     ]
    }
   ],
   "source": [
    "!/usr/src/tensorrt/bin/trtexec --onnx=yolov5n.trt.onnx --saveEngine=yolov5n_320_trtexec.engine --workspace=8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bfee985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're using TensorRT: 8.2.1.8 on cuda device: 0.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cuda_visible = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_visible\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "device = torch.device('cuda')\n",
    "\n",
    "import tensorrt as trt\n",
    "print(f\"We're using TensorRT: {trt.__version__} on {device} device: {cuda_visible}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77629fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine_path = \"yolov5n.engine\"\n",
    "engine_path = \"yolov5n_320_trtexec.engine\"\n",
    "img_size = 320\n",
    "img_path = \"../test/assets/bus.jpg\"\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img,(img_size,img_size))\n",
    "img = img.astype(np.float32)\n",
    "img /= 255\n",
    "img = np.transpose(img,(2,0,1))\n",
    "# img = np.expand_dims(img, axis=0)\n",
    "img = np.ascontiguousarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cb5cbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 320, 320])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor = torch.from_numpy(img).to(device)\n",
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cbf2cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolort.runtime import PredictorTRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c371dd",
   "metadata": {},
   "source": [
    "# 测试 trtexec 导出的 engine 推理速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "692d5763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading yolov5n_320_trtexec.engine for TensorRT inference...\n"
     ]
    }
   ],
   "source": [
    "y_runtime = PredictorTRT(engine_path, device=device)\n",
    "y_runtime.warmup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c14c186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.5 ms ± 364 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "predictions_trt = y_runtime.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2a3afe",
   "metadata": {},
   "source": [
    "# 测试 tensorrt 导出的 engine 推理速度(未完成)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be05e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_runtime = PredictorTRT(engine_path, device=device)\n",
    "y_runtime.warmup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6681d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_trt = y_runtime.predict(img_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
