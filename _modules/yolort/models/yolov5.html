
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../../../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../../../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../../../_static/javascripts/modernizr.js"></script>
  
  
  
    <title>yolort.models.yolov5 &#8212; yolort  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/material.css" />
    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../../../_static/favicon.svg"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=blue data-md-color-accent=light-blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#_modules/yolort/models/yolov5" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../../index.html" title="yolort  documentation"
           class="md-header-nav__button md-logo">
          
              <img src="../../../_static/yolort_logo_icon.png" height="26"
                   alt="yolort documentation logo">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">YOLOv5 Runtime Stack</span>
          <span class="md-header-nav__topic"> yolort.models.yolov5 </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/zhiqwang/yolov5-rt-stack/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    yolort
  </div>
</a>
          </div>
        </div>
      
      
  
  <script src="../../../_static/javascripts/version_dropdown.js"></script>
  <script>
    var json_loc = "../../../"versions.json"",
        target_loc = "../../../../",
        text = "Versions";
    $( document ).ready( add_version_dropdown(json_loc, target_loc, text));
  </script>
  

    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
          <li class="md-tabs__item"><a href="../../../index.html" class="md-tabs__link">yolort  documentation</a></li>
          <li class="md-tabs__item"><a href="../../index.html" class="md-tabs__link">Module code</a></li>
          <li class="md-tabs__item"><a href="../models.html" class="md-tabs__link">yolort.models</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../../index.html" title="yolort documentation" class="md-nav__button md-logo">
      
        <img src="../../../_static/yolort_logo_icon.png" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../../../index.html"
       title="yolort documentation">YOLOv5 Runtime Stack</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/zhiqwang/yolov5-rt-stack/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    yolort
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Getting Started</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../installation.html" class="md-nav__link">Install yolort</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Tutorials</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../notebooks/inference-pytorch-export-libtorch.html" class="md-nav__link">Intuition for yolort</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../notebooks/comparison-between-yolort-vs-yolov5.html" class="md-nav__link">What is the difference between yolort and yolov5</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../notebooks/how-to-align-with-ultralytics-yolov5.html" class="md-nav__link">How to align with ultralytics yolov5</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../notebooks/anchor-label-assignment-visualization.html" class="md-nav__link">Visualize the anchor-target assignment</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../notebooks/model-graph-visualization.html" class="md-nav__link">Visualize model graph</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Deployment</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../notebooks/export-onnx-inference-onnxruntime.html" class="md-nav__link">Deploying yolort on ONNX Runtime</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../notebooks/onnx-graphsurgeon-inference-tensorrt.html" class="md-nav__link">Deploying yolort on TensorRT</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../notebooks/export-relay-inference-tvm.html" class="md-nav__link">Deploying yolort on TVM</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">API Reference</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../models.html" class="md-nav__link">yolort.models</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="../../../models.html#models-structure" class="md-nav__link">Models structure</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../models.html#pre-trained-weights" class="md-nav__link">Pre-trained weights</a>
      
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../yolov5.html" class="md-nav__link">Modules and utils for YOLOv5</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
  <ul class="md-nav__list" data-md-scrollfix="">
  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <h1 id="modules-yolort-models-yolov5--page-root">Source code for yolort.models.yolov5</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) 2021, yolort team. All rights reserved.</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">torchvision.io</span> <span class="kn">import</span> <span class="n">read_image</span>
<span class="kn">from</span> <span class="nn">yolort.data</span> <span class="kn">import</span> <span class="n">contains_any_tensor</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">yolo</span>
<span class="kn">from</span> <span class="nn">.transform</span> <span class="kn">import</span> <span class="n">YOLOTransform</span><span class="p">,</span> <span class="n">_get_shape_onnx</span>
<span class="kn">from</span> <span class="nn">.yolo</span> <span class="kn">import</span> <span class="n">YOLO</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"YOLOv5"</span><span class="p">]</span>


<div class="viewcode-block" id="YOLOv5"><a class="viewcode-back" href="../../../models.html#yolort.models.YOLOv5">[docs]</a><span class="k">class</span> <span class="nc">YOLOv5</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Wrapping the pre-processing (`LetterBox`) into the YOLO models.</span>

<span class="sd">    The input to the model is expected to be a list of tensors, each of shape [C, H, W], one for each</span>
<span class="sd">    image, and should be in 0-1 range. Different images can have different sizes but they will be resized</span>
<span class="sd">    to a fixed size that maintains the aspect ratio before passing it to the backbone.</span>

<span class="sd">    The behavior of the model changes depending if it is in training or evaluation mode.</span>

<span class="sd">    During training, the model expects both the input tensors, as well as a targets (list of dictionary),</span>
<span class="sd">    containing:</span>
<span class="sd">        - boxes (``FloatTensor[N, 4]``): the ground-truth boxes in ``[x1, y1, x2, y2]`` format, with</span>
<span class="sd">          ``0 &lt;= x1 &lt; x2 &lt;= W`` and ``0 &lt;= y1 &lt; y2 &lt;= H``.</span>
<span class="sd">        - labels (Int64Tensor[N]): the class label for each ground-truth box</span>

<span class="sd">    The model returns a Dict[Tensor] during training, containing the classification and regression</span>
<span class="sd">    losses.</span>

<span class="sd">    During inference, the model requires only the input tensors, and returns the post-processed</span>
<span class="sd">    predictions as a List[Dict[Tensor]], one for each input image. The fields of the Dict are as</span>
<span class="sd">    follows, where ``N`` is the number of detections:</span>

<span class="sd">        - boxes (``FloatTensor[N, 4]``): the predicted boxes in ``[x1, y1, x2, y2]`` format, with</span>
<span class="sd">          ``0 &lt;= x1 &lt; x2 &lt;= W`` and ``0 &lt;= y1 &lt; y2 &lt;= H``.</span>
<span class="sd">        - labels (Int64Tensor[N]): the predicted labels for each detection</span>
<span class="sd">        - scores (Tensor[N]): the scores for each detection</span>

<span class="sd">    Example:</span>

<span class="sd">        Demo pipeline for YOLOv5 Inference.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from yolort.models import YOLOv5</span>

<span class="sd">            # Load the yolov5s version 6.0 models</span>
<span class="sd">            arch = 'yolov5_darknet_pan_s_r60'</span>
<span class="sd">            model = YOLOv5(arch=arch, pretrained=True, score_thresh=0.35)</span>
<span class="sd">            model = model.eval()</span>

<span class="sd">            # Perform inference on an image file</span>
<span class="sd">            predictions = model.predict('bus.jpg')</span>
<span class="sd">            # Perform inference on a list of image files</span>
<span class="sd">            predictions2 = model.predict(['bus.jpg', 'zidane.jpg'])</span>

<span class="sd">        We also support loading the custom checkpoints trained from ultralytics/yolov5</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from yolort.models import YOLOv5</span>

<span class="sd">            # Your trained checkpoint from ultralytics</span>
<span class="sd">            checkpoint_path = 'yolov5n.pt'</span>
<span class="sd">            model = YOLOv5.load_from_yolov5(checkpoint_path, score_thresh=0.35)</span>
<span class="sd">            model = model.eval()</span>

<span class="sd">            # Perform inference on an image file</span>
<span class="sd">            predictions = model.predict('bus.jpg')</span>

<span class="sd">    Args:</span>
<span class="sd">        arch (string): YOLO model architecture. Default: None</span>
<span class="sd">        model (nn.Module): YOLO model. Default: None</span>
<span class="sd">        num_classes (int): number of output classes of the model (doesn't including</span>
<span class="sd">            background). Default: 80</span>
<span class="sd">        pretrained (bool): If true, returns a model pre-trained on COCO train2017</span>
<span class="sd">        progress (bool): If True, displays a progress bar of the download to stderr</span>
<span class="sd">        size: (Tuple[int, int]): the minimum and maximum size of the image to be rescaled.</span>
<span class="sd">            Default: (640, 640)</span>
<span class="sd">        size_divisible (int): stride of the models. Default: 32</span>
<span class="sd">        fixed_shape (Tuple[int, int], optional): Padding mode for letterboxing. If set to `True`,</span>
<span class="sd">            the image will be padded to shape `fixed_shape` if specified. Instead the image will</span>
<span class="sd">            be padded to a minimum rectangle to match `min_size / max_size` and each of its edges</span>
<span class="sd">            is divisible by `size_divisible` if it is not specified. Default: None</span>
<span class="sd">        fill_color (int): fill value for padding. Default: 114</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">arch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">80</span><span class="p">,</span>
        <span class="n">pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">progress</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">640</span><span class="p">,</span> <span class="mi">640</span><span class="p">),</span>
        <span class="n">size_divisible</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
        <span class="n">fixed_shape</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fill_color</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">114</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">arch</span> <span class="o">=</span> <span class="n">arch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>

        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">yolo</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">arch</span><span class="p">](</span>
                <span class="n">pretrained</span><span class="o">=</span><span class="n">pretrained</span><span class="p">,</span>
                <span class="n">progress</span><span class="o">=</span><span class="n">progress</span><span class="p">,</span>
                <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">YOLOTransform</span><span class="p">(</span>
            <span class="n">size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">size_divisible</span><span class="o">=</span><span class="n">size_divisible</span><span class="p">,</span>
            <span class="n">fixed_shape</span><span class="o">=</span><span class="n">fixed_shape</span><span class="p">,</span>
            <span class="n">fill_color</span><span class="o">=</span><span class="n">fill_color</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># used only on torchscript mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_has_warned</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">targets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]]]:</span>

        <span class="c1"># get the original image sizes</span>
        <span class="n">original_image_sizes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
                <span class="n">val</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>
                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
                <span class="n">original_image_sizes</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">val</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">val</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

        <span class="c1"># Transform the input</span>
        <span class="n">samples</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="c1"># Compute the detections</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">tensors</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="n">targets</span><span class="p">)</span>

        <span class="n">losses</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">detections</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="c1"># compute the losses</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">is_scripting</span><span class="p">():</span>
                <span class="n">losses</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">losses</span> <span class="o">=</span> <span class="n">outputs</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Rescale coordinate</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">is_scripting</span><span class="p">():</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">outputs</span>

            <span class="k">if</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">_is_tracing</span><span class="p">():</span>
                <span class="n">im_shape</span> <span class="o">=</span> <span class="n">_get_shape_onnx</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">tensors</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">im_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">tensors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>

            <span class="n">detections</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">im_shape</span><span class="p">,</span> <span class="n">original_image_sizes</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">is_scripting</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_warned</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">"YOLOv5 always returns a (Losses, Detections) tuple in scripting."</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_has_warned</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">return</span> <span class="n">losses</span><span class="p">,</span> <span class="n">detections</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">eager_outputs</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">detections</span><span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">unused</span>
    <span class="k">def</span> <span class="nf">eager_outputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
        <span class="n">detections</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]]]:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">losses</span>

        <span class="k">return</span> <span class="n">detections</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">image_loader</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]]:</span>
        <span class="sd">"""</span>
<span class="sd">        Predict function for raw data or processed data</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Input to predict. Can be raw data or processed data.</span>
<span class="sd">            image_loader: Utility function to convert raw data to Tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The post-processed model predictions.</span>
<span class="sd">        """</span>
        <span class="n">image_loader</span> <span class="o">=</span> <span class="n">image_loader</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_loader</span>
        <span class="n">images</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">collate_images</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">image_loader</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">default_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">"""</span>
<span class="sd">        Default loader of read a image path.</span>

<span class="sd">        Args:</span>
<span class="sd">            img_path (str): a image path</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor, processed tensor for prediction.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">read_image</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>

    <span class="k">def</span> <span class="nf">collate_images</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">image_loader</span><span class="p">:</span> <span class="n">Callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="sd">"""</span>
<span class="sd">        Prepare source samples for inference.</span>

<span class="sd">        Args:</span>
<span class="sd">            samples (Any): samples source, support the following various types:</span>
<span class="sd">                - str or List[str]: a image path or list of image paths.</span>
<span class="sd">                - Tensor or List[Tensor]: a tensor or list of tensors.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[Tensor], The processed image samples.</span>
<span class="sd">        """</span>
        <span class="n">p</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>  <span class="c1"># for device and type</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">p</span><span class="p">)]</span>

        <span class="k">if</span> <span class="n">contains_any_tensor</span><span class="p">(</span><span class="n">samples</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">sample</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">samples</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">):</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">image_loader</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
                <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">outputs</span>

        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"The type of the sample is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">}</span><span class="s2">, we currently don't support it now, the "</span>
            <span class="s2">"samples should be either a tensor, list of tensors, a image path or list of image paths."</span>
        <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">load_from_yolov5</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">checkpoint_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">640</span><span class="p">,</span> <span class="mi">640</span><span class="p">),</span>
        <span class="n">size_divisible</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
        <span class="n">fixed_shape</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fill_color</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">114</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">"""</span>
<span class="sd">        Load custom checkpoints trained from YOLOv5.</span>

<span class="sd">        Args:</span>
<span class="sd">            checkpoint_path (str): Path of the YOLOv5 checkpoint model.</span>
<span class="sd">            size: (Tuple[int, int]): the minimum and maximum size of the image to be rescaled.</span>
<span class="sd">                Default: (640, 640)</span>
<span class="sd">            size_divisible (int): stride of the models. Default: 32</span>
<span class="sd">            fixed_shape (Tuple[int, int], optional): Padding mode for letterboxing. If set to `True`,</span>
<span class="sd">                the image will be padded to shape `fixed_shape` if specified. Instead the image will</span>
<span class="sd">                be padded to a minimum rectangle to match `min_size / max_size` and each of its edges</span>
<span class="sd">                is divisible by `size_divisible` if it is not specified. Default: None</span>
<span class="sd">            fill_color (int): fill value for padding. Default: 114</span>
<span class="sd">        """</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">YOLO</span><span class="o">.</span><span class="n">load_from_yolov5</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">yolov5</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
            <span class="n">size_divisible</span><span class="o">=</span><span class="n">size_divisible</span><span class="p">,</span>
            <span class="n">fixed_shape</span><span class="o">=</span><span class="n">fixed_shape</span><span class="p">,</span>
            <span class="n">fill_color</span><span class="o">=</span><span class="n">fill_color</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">yolov5</span></div>
</pre></div>

          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2022, yolort team.
              
          </div>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 4.4.0.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../../../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>